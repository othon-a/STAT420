---
title: "STAT 420 Project - Crop Yield"
author: "Ziquan Wang and Othon Almanza"
date: "2025-12-09"
output:
  pdf_document:
    extra_dependencies: ["float"]
  html_document:
    df_print: paged
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)

suppressPackageStartupMessages({
library(readr)
library(lmtest)
library(MASS)
library(faraway)
library(tidyverse)
library(glmnet)
})

df = read_csv("cleaned_yield_with_gdp_cat.csv")
df_potatoes = subset(df, crop == "Potatoes")
df_potatoes = df_potatoes[, -(1:2)]
```

```{r echo=FALSE}
diagnostic_plots = function(model) {
  
  # 2x2 layout
  par(mfrow = c(2, 2))
  
  fit = fitted(model)
  res = residuals(model)
  
  plot(fit, res,
       xlab = "Fitted values",
       ylab = "Residuals",
       main = "Fitted vs Residuals")
  abline(h = 0, lty = 2, col = "red")
  
  hist(res,
       breaks = 15,
       probability = TRUE,
       main = "Histogram of Residuals",
       xlab = "Residuals")
  curve(dnorm(x, mean(res), sd(res)), add = TRUE, col = "red")
  
  qqnorm(res,
         main = "Normal Q-Q Plot")
  qqline(res, col = "red")
  
  b = boxcox(
    model,
    lambda = seq(-2, 2, 0.1),
    plotit = TRUE
  )
  
}

diagnostic_tests = function(model) {
  
  # Basic quantities
  res = residuals(model)
  n = length(res)
  p = length(coef(model))  
  
  bp = bptest(model)
  
  shapiro = shapiro.test(res)
  
  vif_values = car::vif(model)
  cat("=== Breusch-Pagan Test (Homoscedasticity) ===\n")
  print(bp)
  cat("Interpretation: p-value < 0.05 suggests heteroscedasticity.\n\n\n")
  
  cat("=== Shapiro-Wilk Test (Normality of Residuals) ===\n")
  print(shapiro)
  cat("Interpretation: p-value < 0.05 suggests non-normal residuals.\n\n\n")
  
  cat("=== Variance Inflation Factor (VIF) ===\n\n")
  print(vif_values)
  cat("\nInterpretation: VIF > 5 suggests moderate collinearity; VIF > 10 suggests high multicollinearity.")
}

loocv = function(model) {
  loocv_rmse = c(
    RMSE = sqrt(mean(residuals(model)^2)),
    LOOCV_RMSE = sqrt(mean((resid(model)/(1 - hatvalues(model)))^2))
  )
  
  cat("=== LOOCV-RMSE ===\n\n")
  print(loocv_rmse)
  cat("\nInterpretation: LOOCV-RMSE significantly larger than RMSE may indicate under or over-fitting")
}

boxcox_lambda = function(model) {
  bxcx = boxcox(model)
  lambda = c("Box-Cox Lambda" = bxcx$x[which.max(bxcx$y)])
  print(lambda)
}
```

```{r echo=FALSE}
run_lasso_scaled = function(x, y, family = "gaussian", alpha = 1, seed = 420) {
  
  x_scaled = scale(x)
  y_scaled = scale(y)

  set.seed(seed)
  lasso_fit = glmnet(x = x_scaled, y = y_scaled, family = family, alpha = alpha, standardize = FALSE)
  
  coef_paths = coef(lasso_fit)
  coef_df = as.data.frame(as.matrix(coef_paths))
  
  set.seed(seed)
  cv_fit = cv.glmnet(x = x_scaled, y = y_scaled, family = family, alpha = alpha, standardize = FALSE )
  
  coef_min = coef(cv_fit, s = "lambda.min")
  coef_1se = coef(cv_fit, s = "lambda.1se")
  
  return(list(
    lasso_fit = lasso_fit,
    cv_fit = cv_fit,
    coef_df = coef_df,
    coef_min = coef_min,
    coef_1se = coef_1se
  ))
}
```

## Introduction

Crop yield prediction is an important aspect of agricultural planning that has received greater interest with the advent of machine learning. Using a dataset of crop yields, we analyzed numeric and categorical predictors to uncover patterns that correlate with yield mass. The insight gained from a crop yield analysis can be beneficial in numerous way: It can assist in optimizing farming techniques to maximize crop output. It can also be used to predict crop yields within given conditions, assist in site suitability assessments, and prepare for long-term changes in climate patterns.

Our dataset was acquired from Kaggle and was originally compiled form the Food and Agriculture Organization and the World Bank. Each observation represents a crop yield measured in hectograms per hectare (hg/ha), with accompanying data including the type of crop, country of production, average rainfall, pesticide tonnes, and average temperature.

## Methods

### Data Cleaning

The first step in cleaning the dataset was to remove an index column and identify duplicate observations. Duplicates were found in the dataset and removed. Further, there were duplicates in the data with different temperature values but identical values for all other fields. These instances were each aggregated into a single observation containing the average temperature for the duplicate records. Observations with null values were also removed. Curiously, no data for the year 2003 was provided.

Additional datasets were identified and joined with the core data to supplement the analysis. Country-level gross domestic product (GDP) data was acquired from the World Bank since economic well-being could conceivably improve farming practices and efficiency. Countries were divided into low, middle, and high-income countries using quantile breaks to analyze as a categorical predictor. Additionally, we were concerned about the high granularity of countries as a predictor. To enhance the interpretability of other predictors, we instead categorized countries into subregions by joining this category from a United Nations geoscheme dataset. For the GDP and subregions joins, a few country names had to be manually renamed to match the core dataset (e.g. renaming 'The Bahamas' to 'Bahamas').

Finally, we decided to focus on a single crop for our analysis since different crops are affected differently by the predictors we analyzed. Potatoes had the highest number of observations in our dataset. As a staple in much of the world, it also had the highest geographic distribution. Our final steps in data cleaning involved narrowing the working data to the potato subset, removing the unused country and crop columns, and renaming the remaining columns for usability. The final output was written into its own .csv file.

### Exploratory Data Analysis

Our first step in data exploration involved using cor() and pairs() to identify any trends and obvious collinearity issues (see figure 5 of the appendix). Right away, we found patterns emerging. A strong correlation of 0.63 is seen between GDP and yield, indicating that economic prosperity likely does affect crop output positively. A strong inverse correlation of -0.53 was found between temperature and GDP, illustrating known differences in economic development between the Global North and the Global South. We also see crop yields trending upward over the years, likely due to advances in technology and farming techniques.

```{r echo=FALSE, fig.cap="Trends and patterns box plots"}
par(mfrow = c(2, 2))
gdp_tier_ordered = factor(df_potatoes$gdp_tier, levels = c("Low", "Middle", "High"))
boxplot(df_potatoes$yield_hg_ha ~ gdp_tier_ordered,
        main = "Crop Yield vs Gross Demostic Product",
        xlab = "Gross Domestic Product",
        ylab = "Crop Yield (hg/ha)")

boxplot(df_potatoes$temp_c ~ gdp_tier_ordered,
        main = "Temperature vs Gross Domestic Product",
        xlab = "Gross Domestic Product",
        ylab = "Temperature (in Â°C)")

boxplot(df_potatoes$yield_hg_ha ~ df_potatoes$year,
        main = "Crop Yield vs Year",
        xlab = "Year",
        ylab = "Crop Yield (hg/ha)")
par(mfrow = c(1, 1))
```

Additionally, pairs() uncovered a pattern between pesticides and yield output that might benefit from one or more predictor-level transformations. Temperature might also benefit from a transformation.

```{r, echo=FALSE, results='asis'}
cat("\\clearpage")
```

```{r echo=FALSE, fig.post="H", fig.cap="Candidates for predictor transformations"}
par(mfrow = c(1, 2))
plot(df_potatoes$yield_hg_ha ~ df_potatoes$pesticides_t,
     main = "Yield vs Pesticides",
     xlab = "Pesticides (in Tonnes)",
     ylab = "Yield (hg/ha)")
plot1 = lm(df_potatoes$yield_hg_ha ~ df_potatoes$pesticides_t)

plot(df_potatoes$yield_hg_ha ~ df_potatoes$temp_c,
     main = "Yield vs Temperature",
     xlab = "Temperature (in Degrees Celsius)",
     ylab = "Yield (hg/ha)")
plot1 = lm(df_potatoes$yield_hg_ha ~ df_potatoes$pesticides_t)
par(mfrow = c(1, 1))
```



### Full Linear Model

After exploring the cleaned data, we created a full additive model using yield as a function of the remaining predictors. This achieved a baseline adjusted r-squared of 0.701. The summary output is shown below.

```{r echo=FALSE}
add_model = lm(yield_hg_ha ~ ., data = df_potatoes)
summary(add_model)
```
With an r-squared of 0.7046, our baseline model shows a strong correlation between our predictors and the yield response. This coefficient of determination indicates that 70.46% of the observed variation in yield can be explained by the full additive linear model.

We can also see patterns emerge from the model's coefficients. First, we observe that year is positively correlated with crop yield. When all other predictors are equal, each additional year results in a yield increase of 2,300 hg/ha. We see that rain has a small but positive correlation with crop yield, with an increase of 7.9 hg/ha for every additional millimeter of rainfall. Pesticides are also correlated with increased crop yield, with an increase in 0.6 hg/ha for each additional tonne of pesticides. Temperature reverses these trends, with yield decreases of 2,200 hg/ha for every increase in degrees Celsius, illustrating potato's suitability for cooler climates. Every numeric predictor is statistically significant at a level of alpha = 0.01. The GDP tiers reinforce what we had seen during the data exploration process: The base factor level of high-GDP corresponds with the highest corp yields. The intercept is reduced for middle-GDP observations and reduced even further for low-GDP observations. When we look at the subregion factor, we see that are small but statistically significant variations among the different subregions. The notable exception to this is Western Europe, which has a high p-value of 0.269. This may be due to the inclusion of an Eastern Europe subregion, which likely shares many commonalities with Western Europe regarding climate conditions, economic output, and farming practices. This high p-value indicates the statistical insignificance on the potato yield considering the difference among these two regions as the variable.

In the appendix, we have outputted diagnostics for the full additive model. In figure 6, we see that variance is not equally distributed, but it is not grossly violated either. The residuals seem to follow a relatively normal distribution. Normality in the Q-Q plot looks acceptable. The model could benefit from a Box-Cox transformation. When we run a Breusch-Pagan test of homoscedasticity and a Shapiro-Wilk test of normality, the results suggest that we must reject the assumptions of equal variance and normality. We will try to reach a model that improves on these diagnostics.

We can further validate the full model using leave-one-Out cross-validation (LOOCV). Using hat values to conduct LOOCV, we attain a root mean square error (RMSE) of 73,268.77 hg/ha. This is only slightly larger than the RMSE of the full additive model, 73,154.80 hg/ha, indicating a favorable result. The LOOCV RMSE is necessarily larger than the model's RMSE, but in this case only slightly so.

### Other Methods

We also created a null model that omitted the subregions predictor to evaluate whether it was needed in our final model. This model resulted in a significantly lower adjusted r-squared of 0.464. An ANOVA test confirmed this trend. Using any reasonable significance level resulted in an outcome that rejects the null hypothesis in favor of including subregions. Including subregions was thus taken as a good compromise to build a stronger model without needing to classify crop yields at the country level.

Having identified pesticides as a predictor that might benefit from a transformation, we first observe that log transforming pesticides seems to improve its linear relationship with yield size. We can see the twice transformed pesticides predictor scattered more evenly around the red line after squaring the log transformation.

```{r echo=FALSE, fig.cap="Predictor transformations on pesticides"}
par(mfrow = c(2, 2))
plot(df_potatoes$yield_hg_ha ~ df_potatoes$pesticides_t,
     main = "Yield vs Pesticides",
     xlab = "Pesticides (in Tonnes)",
     ylab = "Yield (hg/ha)")
plot1 = lm(df_potatoes$yield_hg_ha ~ df_potatoes$pesticides_t)
abline(plot1, col = "red")

plot(df_potatoes$yield_hg_ha ~ I(log(df_potatoes$pesticides_t)),
     main = "Yield vs Log Pesticides",
     xlab = "log(pesticides_t)",
     ylab = "Yield (hg/ha)")
plot2 = lm(df_potatoes$yield_hg_ha ~ I(log(df_potatoes$pesticides_t)))
abline(plot2, col = "red")

plot(df_potatoes$yield_hg_ha ~ I(log(df_potatoes$pesticides_t)^2),
     main = "Yield vs Log Pesticides Squared",
     xlab = "I(log(pesticides_t)^2)",
     ylab = "Yield (hg/ha)")
plot3 = lm(df_potatoes$yield_hg_ha ~ I(log(df_potatoes$pesticides_t)^2))
abline(plot3, col = "red")
par(mfrow = c(1, 1))
```

A quadratic transformation was applied to temperature). The result is less significant than the transformation of pesticides predictor. However, the transformed temperature predictor scattered evenly around the red line as well (see figure 7 in the appendix). 

We created an additive model included all predictors and also incorporated predictor-level transformations for pesticides and temperature. We chose to keep only the transformed predictors in the model fitting because the clearly nonlinear relationship between yield and these transformed predictors. We attempted a backward BIC search to see if the model could be reduced from here, but perhaps unsurprisingly, no predictors were dropped. The Adjusted R-squared improved to 0.7457 against 0.701 before transformation. This indicated the predictor transformation helped improving the model. The model returns an RMSE of 50,668.60 hg/ha and a LOOCV-RMSE of 51,263.41 hg/ha, an significant improvement from the full additive model.

Having chosen the predictor transformations to incorporate, we then created a model that created two-way interactions among rain, pesticides, temperature, and GDP. Year and region were kept in the model but not considered for two-way interactions because the subregion could explode the interactive term and make it hard to interpret and it is unlikely Year predictor interact with other predictors observing its relationship with other predictors the plot generated by Pairs() function. This created a large model appropriate for BIC backward search. The search was successful, and the model was reduced to a manageable size. The Adjusted R-squared improved to 0.7643 against 0.7457 before adding interaction terms. The model returns an RMSE of 48,705.68 hg/ha and a LOOCV-RMSE of 49,403.77 hg/ha, an improvement from the full additive transformed model. Additionally, variance inflation factors (VIF's) do not show problematic covariance within the model. Interestingly, the gdp_tier alone became insignificant and the interactive term with gdp_tier are significant, which indicated the gdp_tier's effect on the yield depends on other factors.

Finally, we used boxcox() to find an appropriate Box-Cox transformation on the response. A lambda value of 0.707 was identified and used. However this is where the complication happens. After the response transformation, the Adjusted R-squared dropped from 0.7643 to 0.7477 indicates less variance response transformed model explains. They have a disagreement on the significance of term I(temp_c^2). In the response transformed model, the term I(temp_c^2)'s statistical level was downgraded. 

We decided to leverage LASSO regression predictors selection technique to see which model LASSO regression agrees with regarding the term I(temp_c^2). The LASSO regression was given the same predictor combination. When I choose the lambda value at 0.00375 reducing the betas of some predictors, the term I(temp_c^2) appeared to be zero which indicated it is a weaker predictor than the remaining predictors. Thus, we favor the response transformed model as our final model.

```{r, echo=FALSE, results='asis'}
cat("\\clearpage")
```

```{r echo=FALSE, fig.pose="H", fig.cap="LASSO regression coefficient shrink"}
y_lasso = df_potatoes$yield_hg_ha
x_lasso = model.matrix(yield_hg_ha ~ year + (rain_mm + I((log(pesticides_t))^2) 
                                             + I(temp_c^2) + gdp_tier)^2 +subregion, data = df_potatoes)[, -1]
lasso_results = run_lasso_scaled(x_lasso, y_lasso)
plot(lasso_results$lasso_fit, main = "")
title("LASSO Regression Coef. Shrink Chart", line = 3)
```

Additionally, by comparing the diagnostic plots, the response transformed model appeared to have more evenly distributed fitted vs residuals plot and its histogram of residuals appeared to be more following the normal distribution curve. With these observation and efforts, we chose response transformed model to be our final model.

## Conlusion

Our final model achieves an r-squared of 0.7477, accounting for a larger portion of the response's observed variation compared to the full additive model's r-squared of 0.7046. We see improvements in other diagnostics as well: The model's RMSE is improved from 73,154.80 to 48,705.68. It also shows a favorable LOOCV-RMSE of 49,403.77, suggesting that the model is not compromised by under or over-fitting. Additionally, normality is considerably increased in the final model from a Shapiro-Wilk normality p-value of 0.003364 to a p-value of 0.0209, as seen under figure 11 of the appendix. We also see a more even distribution of the residuals compared to the full additive model. The final model indicates year, rain, pesticides and regions are individually significant predictors even at alpha = 0.001 significance level, with regression coefficients of 44.27, 1.73 and 33.01 respectively for these numerical predictors.

This model reflects many of the trends that we uncovered previously, albeit with higher granularity resulting from interactions. The model still shows that crop yields are positively correlated with year, presumably reflecting advances in farming techniques and technology. Rain still has a slight but positive correlation with yield. Pesticides also remain positively correlated with yield, but interestingly, low-GDP countries see a diminishing return when compared to higher-income countries. Perhaps this is due to the use of lower-quality pesticides. We also see diminishing returns from pesticides when rainfall is considered. It could stand to reason that rainfall washes away pesticides, reducing their effectiveness.

Overall, We believe the updated model is a stronger model for prediction, as well as a sounder model for explanation.

## Future Actions

Regarding the missing 2003 data, we could either find these missing data or interpolate the missing points to see how it affects the model.

Through research, alternative LASSO regression algorithms were identified that better identify the significance of predictors. Though the alternatives were out the scope of this course, they are worth considering in the future.

## Appendix

***Core Data Source***

Crop yield data: https://www.kaggle.com/datasets/patelris/crop-yield-prediction-dataset/discussion/293030

***Additional Data Sources***

GDP data: https://data.worldbank.org/indicator/NY.GDP.PCAP.CD

UN geoscheme subregions: https://unstats.un.org/unsd/methodology/m49/

***Data Exploration using Covariance and Pairs() function***

```{r, echo=FALSE}
df_potatoes_num = df_potatoes%>%        
  mutate(
    gdp_tier = as.numeric(factor(gdp_tier, levels = c("Low", "Middle", "High"))),     
    subregion = as.numeric(factor(subregion))    
  )
```

```{r}
round(cor(df_potatoes_num), 2)
```

```{r, echo=FALSE, results='asis'}
cat("\\clearpage")
```

```{r, fig.pose="H", fig.cap="Pair scatterplots"}
pairs(df_potatoes_num)
```

***Fitting and diagnosing the full model***

```{r, echo=FALSE, results='asis'}
cat("\\clearpage")
```

```{r, fig.post="H", fig.cap="Diagnosic plots for full additive model"}
add_model = lm(yield_hg_ha ~ ., data = df_potatoes)

diagnostic_plots(add_model)
```

```{r}
diagnostic_tests(add_model)
```

```{r}
loocv(add_model)
```

***Testing subregion significance***

```{r}
add_nosubreg = lm(yield_hg_ha ~ . - subregion, data = df_potatoes)

anova(add_nosubreg, add_model)
```

***Temperature Predictor transformation***

```{r, echo=FALSE, fig.pos="H", fig.cap="Predictor transformation on temperature", out.width="100%", out.height="40%"}
par(mfrow = c(1, 2))
plot(df_potatoes$yield_hg_ha ~ df_potatoes$temp_c,
     main = "Yield vs Temperature",
     xlab = "Temperature (in Tonnes)",
     ylab = "Yield (hg/ha)")
temp1 = lm(df_potatoes$yield_hg_ha ~ df_potatoes$temp_c)
abline(temp1, col = "red")

plot(df_potatoes$yield_hg_ha ~ I(df_potatoes$temp_c^2),
     main = "Yield vs Temperature",
     xlab = "I(temp_c^2)",
     ylab = "Yield (hg/ha)")
temp2 = lm(df_potatoes$yield_hg_ha ~ I(df_potatoes$temp_c^2))
abline(temp2, col = "red")
par(mfrow = c(1, 1))
```

***Fit the model with all transformed predictors and BIC model reduction ***

```{r}
tran_model = lm(yield_hg_ha ~ year + rain_mm + I((log(pesticides_t))^2) 
                + I(temp_c^2) + gdp_tier +subregion, data = df_potatoes)

summary(step(tran_model, direction = "backward", k=log(length(resid(tran_model))), trace = 0))
```

```{r}
loocv(tran_model)
```

***Fit the model with interactive transformed predictors and BIC model reduction ***

```{r}
int_model = lm(yield_hg_ha ~ year + (rain_mm + I((log(pesticides_t))^2) + I(temp_c^2)
                                     + gdp_tier)^2 +subregion , data = df_potatoes)

bic_model = step(int_model, direction = "backward", k=log(length(resid(int_model))), trace = 0)

summary(bic_model)
```

```{r}
car::vif(bic_model)
```

```{r, echo=FALSE, results='asis'}
cat("\\clearpage")
```

```{r, fig.pose="H", fig.cap="Diagnostic plots for BIC model"}
diagnostic_plots(bic_model)
```

```{r}
loocv(bic_model)
```

```{r, echo=FALSE, results='asis'}
cat("\\clearpage")
```

***Using a Box-Cox transformation on the yield response***

```{r, fig.pose="H", fig.cap="Lambda for Box-Cox transformation of yield response"}
boxcox_lambda(bic_model)
```

***Final model and diagnostics***

```{r}
final_model = lm(yield_hg_ha^.707 ~ year + rain_mm + I((log(pesticides_t))^2) + I(temp_c^2) + 
                   gdp_tier + subregion + rain_mm:I((log(pesticides_t))^2) + 
                   rain_mm:gdp_tier + I((log(pesticides_t))^2):I(temp_c^2) + 
                   I((log(pesticides_t))^2):gdp_tier, data = df_potatoes)

summary(final_model)
```

```{r, echo=FALSE, results='asis'}
cat("\\clearpage")
```

```{r, fig.pose="H", fig.cap="LASSO CV fit"}
plot(lasso_results$cv_fit)
coef_32para = coef(lasso_results$cv_fit, s = 0.00375)
coef_32para 
```

```{r, echo=FALSE, results='asis'}
cat("\\clearpage")
```

```{r, fig.pose="H", fig.cap="Diagnostic plots for final model"}
diagnostic_plots(final_model)
```

```{r}
diagnostic_tests(final_model)
```